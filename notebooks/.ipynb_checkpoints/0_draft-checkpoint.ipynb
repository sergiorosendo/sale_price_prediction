{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_column_names_from_ColumnTransformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7173b770631d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_column_names_from_ColumnTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_column_names_from_ColumnTransformer'"
     ]
    }
   ],
   "source": [
    "from src.features.transformers import get_column_names_from_ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../house_sales.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns plot location x price\n",
    "ax = sns.scatterplot(df['longitude'], df['latitude'], hue=df['price'])\n",
    "ax.set(title='Location x Price', xlabel='Longitude', ylabel='Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In our data set we have the following features:\n",
    "    - num_bed: the number of bedrooms\n",
    "    - num_bath: number of bathrooms (fractions mean the house has a toilet-only or shower/bathtub-only bathroom)\n",
    "- **size_house** (includes basement) - The size of the house\n",
    "- **size_lot** - The size of the lot\n",
    "- **num_floors** - The number of floors\n",
    "- **condition** - How worn out the house is. Ranges from 1 (needs repairs all over the place) to 5 (the house is very well maintained)\n",
    "- **size_basement** - The size of the basement\n",
    "- **year_built** - The year the house was built\n",
    "- **renovation_date** - The year the house was renovated for the last time. 0 means the house has never been renovated\n",
    "- **latitude** - Latitude\n",
    "- **longitude** - Longitude\n",
    "- **avg_size_neighbor_houses** - The average house size of the neighbors\n",
    "- **avg_size_neighbor_lot** - The average lot size of the neighbors\n",
    "\n",
    "- **is_waterfront** - Whether or not the house is a waterfront house (0 means it is not a waterfront house whereas 1 means that it is a waterfront house)\n",
    "- **zip** - The zip code\n",
    "\n",
    "price - The last price the house was sold for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()['price'].sort_values()\n",
    "sns.heatmap(df.corr(), cmap=plt.cm.Reds)\n",
    "#figure(num=None, figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.scatterplot(x=corr.index.values.tolist(), y=corr.values)\n",
    "ax.set(title='Correlation: Feature x Price', xlabel='Feature',  ylabel='Correlation')\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), rotation=0);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the graph above that houses in higher latitudes tend to have bigger prices. The longitude itself does not play a major role in the house price, it only seems to matter when it indicates that the house is near the margin of some blank areas, so the its lower correlation with the price tag makes sense. \n",
    "\n",
    "Longitude seems to matter only considering its correlation with the house's proximity to some blank areas. Considering similar longitudes, houses close to the margin of these areas are more expensive, while those inbetween margins dont vary much in price. Assuming that these blank areas are water (they could also be public spaces or green areas), the real information here is in the house's waterfront status, not the longitude. So lets check that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the impact, on price, of the average size of neighbor houses and the size of the house itself is very similar. Possibly, the sizes of neighbor houses are too good estimators for the size of the house, in which case this average value ultimately would work as a second representation of the house size. \n",
    "\n",
    "Lets see if we can confirm this with the house size by location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that the number of bathrooms has a positive correlation with the house price. Since houses with more bathrooms are more valued by buyers, this makes sense. \n",
    "\n",
    "We can assume that this representation was intended. For instance, a house with 1.5 bathrooms could, for instance, mean that it has a normal sized bathroom and a very small one, or it could mean that it has a full fledged bathroom and another one with just a toiled seat and a lavatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that the number of bathrooms has a positive correlation with the house price. Since houses with more bathrooms are more valued by buyers, this makes total sense. \n",
    "\n",
    "This and the fact that non-integer values have similar behavior to their adjacent ones, makes it safe to assume that the data was well measured and that this way of representation was intended.\n",
    "\n",
    "So, it is safe to assume that the data was well measured and that this way of representation was intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_coeff = pd.concat([pd.DataFrame(df.drop(columns='price').columns, columns=['Feature']), pd.DataFrame(np.transpose(clf.coef_), columns=['Coefficient'])], axis = 1)\n",
    "reg_coeff.set_index(keys='Feature', inplace=True)\n",
    "reg_coeff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import metrics\n",
    "print('LR Scores:')\n",
    "#print('Adjusted rand: %.4f' % (metrics.adjusted_rand_score(y_test, y_pred)))\n",
    "#print('Adjusted Mutual info: %.4f' % (metrics.adjusted_mutual_info_score(y_test, y_pred)))\n",
    "#print('Completeness: %.4f' % (metrics.completeness_score(y_test, y_pred)))\n",
    "#print('Fowlkes Mallows: %.4f' % (metrics.fowlkes_mallows_score(y_test, y_pred)))\n",
    "#print('Homogeneity: %.4f' % (metrics.homogeneity_score(y_test, y_pred)))\n",
    "#print('Mutual Info: %.4f' % (metrics.mutual_info_score(y_test, y_pred)))\n",
    "#print('Normalized Mutual info: %.4f' % (metrics.normalized_mutual_info_score(y_test, y_pred)))\n",
    "#print('V measure: %.4f' % (metrics.v_measure_score(y_test, y_pred)))\n",
    "print('chi2: %.4f' % (metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def get_column_names_from_ColumnTransformer(column_transformer):    \n",
    "    col_name = []\n",
    "    for transformer_in_columns in column_transformer.transformers_[:-1]:\n",
    "        #the last transformer is ColumnTransformer's 'remainder'\n",
    "        raw_col_name = transformer_in_columns[2]\n",
    "        if isinstance(transformer_in_columns[1],Pipeline): \n",
    "            transformer = transformer_in_columns[1].steps[-1][1]\n",
    "        else:\n",
    "            transformer = transformer_in_columns[1]\n",
    "        try:\n",
    "            names = transformer.get_feature_names()\n",
    "        except AttributeError: # if no 'get_feature_names' function, use raw column name\n",
    "            names = raw_col_name\n",
    "        if isinstance(names,np.ndarray): # eg.\n",
    "            col_name += names.tolist()\n",
    "        elif isinstance(names,list):\n",
    "            col_name += names    \n",
    "        elif isinstance(names,str):\n",
    "            col_name.append(names)\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scatter_plot(df, x, y):\n",
    "\n",
    "    ax = sns.scatterplot(x=df[x], y=df[y], edgecolor=None)\n",
    "    ax.set(title=x.capitalize() + ' x ' + y.capitalize(), xlabel=x.capitalize(), ylabel=y.capitalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_names_from_ColumnTransformer(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat\n",
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = plt.scatter(df['latitude'], df['price'], s=10)#plt.xlim(0, 6000)\n",
    "plt.title('House size x Price')\n",
    "plt.xlabel('Size')\n",
    "plt.ylabel('Price')\n",
    "plt.show();\n",
    "#long\n",
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = plt.scatter(df['longitude'], df['price'], s=10)#plt.xlim(0, 6000)\n",
    "plt.title('House size x Price')\n",
    "plt.xlabel('Size')\n",
    "plt.ylabel('Price')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pearson Coefficient: %.4f' % df.corr().loc['size_house', 'price'])\n",
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.regplot(x='size_house', y='price', data=df, scatter_kws={'s':2})\n",
    "ax.set(title='House Size x Price', xlabel='Houses size', ylabel='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pearson Coefficient: %.4f' % df.corr().loc['avg_size_neighbor_houses', 'price'])\n",
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.regplot(x='avg_size_neighbor_houses', y='price', data=df, scatter_kws={'s':2})\n",
    "ax.set(title='Avg. Neig. Houses Size x Price', xlabel='Average neighbor houses size', ylabel='Price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This feature is also highly correlated to the size of the lot of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pearson corr. with house size: %.2f' % pearsonr(df['size_lot'], df['avg_size_neighbor_lot'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Similar to the house size, the correlation between the average size of nearby lots and the size of the lot itself is quite high. \n",
    "\n",
    "In the prediction model, it may be best to use only one of these as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Quality\n",
    "Now that we have a built trained model lets see how well it predicted the price for the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(8, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = sns.regplot(x=y_test, y=y_pred, scatter_kws={'s':2})\n",
    "ax.set(title='Real price x Predicted', xlabel='Real Price', ylabel='Predicted Price');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define our preprocessor and classifier to be used in the model. \n",
    "\n",
    "The preprocessor applies transformations to our features. It completes missing values with the mean or with the most-frequent class (for non-numeric variables). It also standardizes the distribution for numerics, for better model performance, and applies one hot-encoding for categoricals. Data standarization improves the model's performance.\n",
    "For numerics, it fill missing values with the mean and, to improve model performance, standardizes their distributions. \n",
    "\n",
    "For categoricals it fill gaps with the most frequent class feature and applies one-hot-encoding. One-hot-encoding converts categorical classes to a numeric representation, so that they can be used by our model. A feature with 3 classes, for instace, after encoding will result in 3 boolean features that indicate the class of an element, these new features containing 1 or 0 will be the ones used to fit our model.\n",
    "\n",
    "The classifier used will be linear regression, as our data exploration showed a good linear relation between the features and the target variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
